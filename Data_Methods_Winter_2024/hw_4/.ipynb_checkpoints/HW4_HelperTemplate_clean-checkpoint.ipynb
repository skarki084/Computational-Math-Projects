{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p5dL4YeVorzV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shlizee/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/shlizee/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 6): Library not loaded: @rpath/libpng16.16.dylib\n",
      "  Referenced from: /Users/shlizee/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: Incompatible library version: image.so requires version 56.0.0 or later, but libpng16.16.dylib provides version 54.0.0'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "feGo1EKE4sRg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 26421880/26421880 [00:02<00:00, 11491415.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 181161.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 4422102/4422102 [00:01<00:00, 3304408.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 9748206.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "106\n",
      "12\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the following code to load and normalize the dataset for training and testing\n",
    "# It will downlad the dataset into data subfolder (change to your data folder name)\n",
    "train_dataset = torchvision.datasets.FashionMNIST('data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST('data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "\n",
    "# Use the following code to create a validation set of 10%\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_dataset)),\n",
    "    train_dataset.targets,\n",
    "    stratify=train_dataset.targets,\n",
    "    test_size=0.1,\n",
    ")\n",
    "\n",
    "# Generate training and validation subsets based on indices\n",
    "train_split = Subset(train_dataset, train_indices)\n",
    "val_split = Subset(train_dataset, val_indices)\n",
    "\n",
    "\n",
    "# set batches sizes\n",
    "train_batch_size = 512 #Define train batch size\n",
    "test_batch_size  = 256 #Define test batch size (can be larger than train batch size)\n",
    "\n",
    "\n",
    "# Define dataloader objects that help to iterate over batches and samples for\n",
    "# training, validation and testing\n",
    "train_batches = DataLoader(train_split, batch_size=train_batch_size, shuffle=True)\n",
    "val_batches = DataLoader(val_split, batch_size=train_batch_size, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "                                           \n",
    "num_train_batches=len(train_batches)\n",
    "num_val_batches=len(val_batches)\n",
    "num_test_batches=len(test_batches)\n",
    "\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_val_batches)\n",
    "print(num_test_batches)\n",
    "\n",
    "\n",
    "#Sample code to visulaize the first sample in first 16 batches \n",
    "\n",
    "# batch_num = 0\n",
    "# for train_features, train_labels in train_batches:\n",
    "    \n",
    "#     if batch_num == 16:\n",
    "#         break    # break here\n",
    "    \n",
    "#     batch_num = batch_num +1\n",
    "#     print(f\"Feature batch shape: {train_features.size()}\")\n",
    "#     print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "    \n",
    "#     img = train_features[0].squeeze()\n",
    "#     label = train_labels[0]\n",
    "#     plt.imshow(img, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "#     print(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "\n",
    "# Sample code to plot N^2 images from the dataset\n",
    "# def plot_images(XX, N, title):\n",
    "#     fig, ax = plt.subplots(N, N, figsize=(8, 8))\n",
    "    \n",
    "#     for i in range(N):\n",
    "#       for j in range(N):\n",
    "#         ax[i,j].imshow(XX[(N)*i+j], cmap=\"Greys\")\n",
    "#         ax[i,j].axis(\"off\")\n",
    "#     fig.suptitle(title, fontsize=24)\n",
    "\n",
    "# plot_images(train_dataset.data[:64], 8, \"First 64 Training Images\" )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HrvoPg1f7Gxu"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3673009256.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    #Define how your model processes the input\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Define your (As Cool As It Gets) Fully Connected Neural Network \n",
    "class ACAIGFCN(nn.Module):\n",
    "    #Initialize model layers, add additional arguments to adjust\n",
    "    def __init__(self, input_dim, output_dim): \n",
    "        super(Network, self).__init__()\n",
    "        #Define the network layer(s) and activation function(s)\n",
    " \n",
    "    def forward(self, input):\n",
    "        #Define how your model propagates the input through the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0F_DyktW8Bgw"
   },
   "outputs": [],
   "source": [
    "# Initialize neural network model with input, output and hidden layer dimensions\n",
    "model = ACAIGFCN(input_dim = 784, output_dim = 10) #... add more parameters\n",
    "                \n",
    "# Define the learning rate and epochs number\n",
    "learning_rate =\n",
    "epochs =\n",
    "\n",
    "\n",
    "train_loss_list = np.zeros((epochs,))\n",
    "validation_accuracy_list = np.zeros((epochs,))\n",
    "\n",
    "# Define loss function  and optimizer\n",
    "loss_func = # Use Cross Entropy loss from torch.nn \n",
    "optimizer = # Use optimizers from torch.optim\n",
    "\n",
    "\n",
    "# Iterate over epochs, batches with progress bar and train+ validate the ACAIGFCN\n",
    "# Track the loss and validation accuracy\n",
    "for epoch in tqdm.trange(epochs):\n",
    "\n",
    "    # ACAIGFCN Training \n",
    "    for train_features, train_labels in train_batches:\n",
    "        # Set model into training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Reshape images into a vector\n",
    "        train_features = train_features.reshape(-1, 28*28)\n",
    "\n",
    "        # Reset gradients, Calculate training loss on model \n",
    "        # Perfrom optimization, back propagation\n",
    " \n",
    "    # Record loss for the epoch\n",
    "    \n",
    "    # ACAIGFCN Validation\n",
    "    for val_features, val_labels in val_batches:\n",
    "        \n",
    "        # Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            \n",
    "             # Reshape validation images into a vector\n",
    "            val_features = val_features.reshape(-1, 28*28)\n",
    "          \n",
    "            # Compute validation outputs (targets) \n",
    "            # and compute accuracy \n",
    "            \n",
    "    # Record accuracy for the epoch; print training loss, validation accuracy\n",
    "    print(\"Epoch: \"+ str(epoch) +\"; Validation Accuracy:\" + str(val_acc/num_val_batches*100) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation accuracy throughout the training epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy on test set\n",
    "\n",
    "# Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for test_features, test_labels in test_batches:\n",
    "\n",
    "        model.eval()\n",
    "        # Reshape test images into a vector\n",
    "        test_features = test_features.reshape(-1, 28*28)\n",
    "\n",
    "         # Compute validation outputs (targets) \n",
    "         # and compute accuracy \n",
    "    \n",
    "    # Compute total (mean) accuracy\n",
    "    # Report total (mean) accuracy, can also compute std based on batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EM6GQLv6j5uH"
   ],
   "name": "Lab 2- PyTorch Basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
