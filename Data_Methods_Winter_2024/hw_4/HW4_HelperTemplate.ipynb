{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p5dL4YeVorzV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samip\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#trying to use GPU\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "feGo1EKE4sRg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "12\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Use the following code to load and normalize the dataset for training and testing\n",
    "# It will downlad the dataset into data subfolder (change to your data folder name)\n",
    "train_dataset = torchvision.datasets.FashionMNIST('data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST('data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "\n",
    "# Use the following code to create a validation set of 10%\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_dataset)),\n",
    "    train_dataset.targets,\n",
    "    stratify=train_dataset.targets,\n",
    "    test_size=0.1,\n",
    ")\n",
    "\n",
    "# Generate training and validation subsets based on indices\n",
    "train_split = Subset(train_dataset, train_indices)\n",
    "val_split = Subset(train_dataset, val_indices)\n",
    "\n",
    "\n",
    "# set batches sizes\n",
    "train_batch_size = 512 #Define train batch size\n",
    "test_batch_size  = 256 #Define test batch size (can be larger than train batch size)\n",
    "\n",
    "\n",
    "# Define dataloader objects that help to iterate over batches and samples for\n",
    "# training, validation and testing\n",
    "train_batches = DataLoader(train_split, batch_size=train_batch_size, shuffle=True)\n",
    "val_batches = DataLoader(val_split, batch_size=train_batch_size, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "                                           \n",
    "num_train_batches=len(train_batches)\n",
    "num_val_batches=len(val_batches)\n",
    "num_test_batches=len(test_batches)\n",
    "\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_val_batches)\n",
    "print(num_test_batches)\n",
    "\n",
    "\n",
    "#Sample code to visulaize the first sample in first 16 batches \n",
    "\n",
    "# batch_num = 0\n",
    "# for train_features, train_labels in train_batches:\n",
    "    \n",
    "#     if batch_num == 16:\n",
    "#         break    # break here\n",
    "    \n",
    "#     batch_num = batch_num +1\n",
    "#     print(f\"Feature batch shape: {train_features.size()}\")\n",
    "#     print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "    \n",
    "#     img = train_features[0].squeeze()\n",
    "#     label = train_labels[0]\n",
    "#     plt.imshow(img, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "#     print(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "\n",
    "# Sample code to plot N^2 images from the dataset\n",
    "# def plot_images(XX, N, title):\n",
    "#     fig, ax = plt.subplots(N, N, figsize=(8, 8))\n",
    "    \n",
    "#     for i in range(N):\n",
    "#       for j in range(N):\n",
    "#         ax[i,j].imshow(XX[(N)*i+j], cmap=\"Greys\")\n",
    "#         ax[i,j].axis(\"off\")\n",
    "#     fig.suptitle(title, fontsize=24)\n",
    "\n",
    "# plot_images(train_dataset.data[:64], 8, \"First 64 Training Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HrvoPg1f7Gxu"
   },
   "outputs": [],
   "source": [
    "#Define your (As Cool As It Gets) Fully Connected Neural Network \n",
    "class ACAIGFCN(nn.Module):\n",
    "    #Initialize model layers, add additional arguments to adjust\n",
    "    def __init__(self, input_dim, output_dim, hidden1_dim, hidden2_dim): \n",
    "        super(ACAIGFCN, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Linear(input_dim, hidden1_dim)\n",
    "        self.layer2 = torch.nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.layer3 = torch.nn.Linear(hidden2_dim, output_dim)\n",
    "        \n",
    "#Define the network layer(s) and activation function(s)\n",
    "    def forward(self, x):\n",
    "            #Define how your model propagates the input through the network\n",
    "            out1 = torch.nn.functional.relu(self.layer1(x))\n",
    "            out2 = torch.nn.functional.relu(self.layer2(out1))\n",
    "            output = self.layer3(out2)\n",
    "            \n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0F_DyktW8Bgw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Validation Accuracy:0.7019927725195885%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network model with input, output and hidden layer dimensions\n",
    "model = ACAIGFCN(input_dim = 784, output_dim = 10, hidden1_dim = 100, hidden2_dim = 100) #... add more parameters\n",
    "                \n",
    "# Define the learning rate and epochs number\n",
    "learning_rate = 1\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "train_loss_list = np.zeros((epochs,))\n",
    "validation_accuracy_list = np.zeros((epochs,))\n",
    "\n",
    "# Define loss function  and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()# Use Cross Entropy loss from torch.nn \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)# Use optimizers from torch.optim\n",
    "\n",
    "\n",
    "# Iterate over epochs, batches with progress bar and train+ validate the ACAIGFCN\n",
    "# Track the loss and validation accuracy\n",
    "for epoch in tqdm.trange(epochs):\n",
    "\n",
    "    # ACAIGFCN Training \n",
    "    for train_features, train_labels in train_batches:\n",
    "        # Set model into training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Reshape images into a vector\n",
    "        train_features = train_features.reshape(-1, 28*28)\n",
    "\n",
    "        # Reset gradients, Calculate training loss on model\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_outputs = model(train_features)\n",
    "        loss = loss_func(train_outputs, train_labels)\n",
    "        # Perfrom optimization, back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "    # Record loss for the epoch\n",
    "    train_loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # ACAIGFCN Validation\n",
    "    for val_features, val_labels in val_batches:\n",
    "        \n",
    "        # Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            \n",
    "             # Reshape validation images into a vector\n",
    "            val_features = val_features.reshape(-1, 28*28)\n",
    "          \n",
    "            # Compute validation outputs (targets)\n",
    "            validation_outputs = model(val_features)\n",
    "            # and compute accuracy \n",
    "            correct = (torch.argmax(validation_outputs, dim=1) == \n",
    "                   val_labels).type(torch.FloatTensor)\n",
    "            validation_accuracy_list[epoch] = correct.mean()\n",
    "            \n",
    "    # Record accuracy for the epoch; print training loss, validation accuracy\n",
    "    val_acc = validation_accuracy_list[epoch]\n",
    "    num_val_batches = len(val_batches)\n",
    "    print(\"Epoch: \"+ str(epoch) +\"; Validation Accuracy:\" + str(val_acc/num_val_batches*100) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation accuracy throughout the training epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy on test set\n",
    "\n",
    "# Telling PyTorch we aren't passing inputs to network for training purpose\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for test_features, test_labels in test_batches:\n",
    "\n",
    "        model.eval()\n",
    "        # Reshape test images into a vector\n",
    "        test_features = test_features.reshape(-1, 28*28)\n",
    "\n",
    "         # Compute validation outputs (targets) \n",
    "         # and compute accuracy \n",
    "    \n",
    "    # Compute total (mean) accuracy\n",
    "    # Report total (mean) accuracy, can also compute std based on batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EM6GQLv6j5uH"
   ],
   "name": "Lab 2- PyTorch Basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
